$schema: https://azuremlschemas.azureedge.net/latest/pipelineJob.schema.json
type: pipeline

experiment_name: llma2-fine-tuning
description: llma2-fine-tuning
inputs:
  num_examples: 2000 #update this to the number of examples you want to use for fine tuning
  model_dir: 
    path: azureml://registries/azureml-meta/models/Llama-2-7b/versions/5
outputs:
  # map the output of the fine tuning job to the output of pipeline job so that we can easily register the fine tuned model
  # registering the model is required to deploy the model to an online or batch endpoint
  trained_model:
jobs:
  train:
    type: command
    code: ./
    command: >-
      python main.py
      --model_dir ${{inputs.model_dir}}
      --epochs ${{inputs.epochs}}
      --num_examples ${{inputs.num_examples}}
      --trained_model ${{outputs.output_dir}}
    inputs:
      epochs: 1
      num_examples: ${{parent.inputs.num_examples}}
      model_dir: ${{parent.inputs.model_dir}} 
    environment: 
      conda_file: ./conda.yml
      image: mcr.microsoft.com/azureml/curated/acft-hf-nlp-gpu
    outputs:
      output_dir: ${{parent.outputs.trained_model}}
    compute: azureml:NC48adsA100 #update NC48adsA100 to the name of your compute target 

    distribution:
      type: pytorch
      process_count_per_instance: 2 #update this to the number of GPUs on your compute target
    resources:
      instance_count: 1 #update this to the number of nodes in your cluster
