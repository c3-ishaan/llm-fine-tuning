{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after training the model, we can use this file to test the model. RUn this notebook in A100 GPU machine (NC24adsA100 compute instance) with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "import time\n",
    "from azure.ai.ml import MLClient, Input\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml import load_component\n",
    "credential = DefaultAzureCredential()\n",
    "subscription_id = \"\" # your subscription id\n",
    "resource_group = \"\" #your resource group\n",
    "workspace = \"\" #your workspace name\n",
    "workspace_ml_client = MLClient(credential, subscription_id, resource_group, workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"llama2_13b_fine_tuned\"\n",
    "model_path=\"./\"\n",
    "workspace_ml_client.models.download(model_name, version=\"2\",download_path=model_path)\n",
    "#after this step, remove the redundant parent folder name \"llama2_13b_fine_tuned\" so that the downloaded folder only has one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "model = mlflow.pyfunc.load_model(model_name)\n",
    "prompt = \"\"\"\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Generate a chessboard with the given size and with pieces at the specified positions.\n",
    "### Input:\n",
    "Size: 8x8 \\nPiece positions:\\nWhite Rook at H8\\nWhite Pawn at B3\\nBlack Pawn at A3\\nBlack Rook at H2\n",
    "\n",
    "\"\"\"\n",
    "model_input= {\"text\":[prompt], \"max_length\":100}\n",
    "model.predict(model_input)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
