$schema: https://azuremlschemas.azureedge.net/latest/pipelineJob.schema.json
type: pipeline

experiment_name: llma2-fine-tuning
description: llma2-fine-tuning
inputs:
  num_examples: 56000 #update this to the number of examples you want to use for fine tuning
  train_path: data/train.jsonl #update this to the path of your training data
  test_path: data/test.jsonl #update this to the path of your test data
  special_token_path: data/tokens.json #update this to the path of your special tokens file
  model_name: llama2_13b_fine_tuned
  chat_model: False #whether to use the chat model or base model. The format of input data is different between the two models
  model_dir: 
    path: azureml://registries/azureml-meta/models/Llama-2-13b/versions/9
outputs:
  # map the output of the fine tuning job to the output of pipeline job so that we can easily register the fine tuned model
  # registering the model is required to deploy the model to an online or batch endpoint
  trained_model:
jobs:
  train:
    type: command
    code: ./
    command: >-
      python finetune_hf_llm.py
      --model_dir ${{inputs.model_dir}}
      --trained_model ${{outputs.output_dir}}
      --model_name ${{inputs.model_name}}
      --chat_model ${{inputs.chat_model}}
      --train_path ${{inputs.train_path}}
      --special_token_path ${{inputs.special_token_path}}
      --test_path ${{inputs.test_path}}

    inputs:
      epochs: 2
      num_examples: ${{parent.inputs.num_examples}}
      model_dir: ${{parent.inputs.model_dir}} 
      model_name: ${{parent.inputs.model_name}}
      chat_model: ${{parent.inputs.chat_model}}
      train_path: ${{parent.inputs.train_path}}
      test_path: ${{parent.inputs.test_path}}
      special_token_path: ${{parent.inputs.special_token_path}}
    environment: 
      conda_file: ./conda.yml
      image: mcr.microsoft.com/azureml/curated/acft-hf-nlp-gpu
    outputs:
      output_dir: ${{parent.outputs.trained_model}}
    compute: azureml:StandardND40rsv2 #update NC48adsA100 to the name of your compute target 

    distribution:
      type: pytorch
      process_count_per_instance: 8 #update this to the number of GPUs on your compute target
    resources:
      instance_count: 1 #update this to the number of nodes in your cluster
