{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example running fine-tuning on Azure Open AI's SQL query generation problem.\n",
    "We use the same base dataset sql_examples.jsonl "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "#load raw data\n",
    "sql_raw = pd.read_json(\"../llama2/data/sql_examples.jsonl\", lines=True).to_dict(orient=\"records\") # load raw data from jsonl file\n",
    "template= '{{\"messages\": [{{\"role\": \"system\", \"content\": \"You are querying the sales database, what is the SQL query for the following input question?\"}}, {{\"role\": \"user\", \"content\": \"{question}\"}}, {{\"role\": \"assistant\", \"content\": \"{sql_query}\"}}]}}'\n",
    "#apply the template to the raw data\n",
    "sql_data = [template.format(question=d[\"question\"], sql_query=d[\"sql_query\"]) for d in sql_raw]\n",
    "#save the data to a jsonl file\n",
    "sql_data_train, sql_data_test = train_test_split(sql_data, test_size=0.2, random_state=42) \n",
    "with open(\"../data/sql_examples_training.jsonl\", \"w\") as f:\n",
    "    for line in sql_data_train:\n",
    "        f.write(line + \"\\n\")\n",
    "with open(\"../data/sql_examples_validation.jsonl\", \"w\") as f:\n",
    "    for line in sql_data_test:\n",
    "        f.write(line + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ.get(\"AZURE_OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file ID: file-2436f03af32c437ab609a1f79a9598de\n",
      "Validation file ID: file-fbf685b8f1184d989fd5d42e897a6f49\n"
     ]
    }
   ],
   "source": [
    "# Upload fine-tuning files\n",
    "\n",
    "import openai\n",
    "import os\n",
    "import openai\n",
    "import os\n",
    "from pathlib import Path  \n",
    "import json\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "env_path = Path('../utils') / 'secrets.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "openai.api_key =  os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "openai.api_base =  os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2023-07-01-preview\"\n",
    "\n",
    "\n",
    "training_file_name = '../data/sql_examples_training.jsonl'\n",
    "validation_file_name = '../data/sql_examples_validation.jsonl'\n",
    "\n",
    "# Upload the training and validation dataset files to Azure OpenAI with the SDK.\n",
    "\n",
    "training_response = openai.File.create(\n",
    "    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\", user_provided_filename=\"sql_examples_training.jsonl\"\n",
    ")\n",
    "training_file_id = training_response[\"id\"]\n",
    "\n",
    "validation_response = openai.File.create(\n",
    "    file=open(validation_file_name, \"rb\"), purpose=\"fine-tune\", user_provided_filename=\"sql_examples_validation.jsonl\"\n",
    ")\n",
    "validation_file_id = validation_response[\"id\"]\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "Resource not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\janguy\\OneDrive - Microsoft\\Documents\\projects\\developments\\llm-fine-tuning\\azureopenai\\fine_tunining.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/janguy/OneDrive%20-%20Microsoft/Documents/projects/developments/llm-fine-tuning/azureopenai/fine_tunining.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mFineTuningJob\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/janguy/OneDrive%20-%20Microsoft/Documents/projects/developments/llm-fine-tuning/azureopenai/fine_tunining.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     training_file\u001b[39m=\u001b[39;49mtraining_file_id,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/janguy/OneDrive%20-%20Microsoft/Documents/projects/developments/llm-fine-tuning/azureopenai/fine_tunining.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     validation_file\u001b[39m=\u001b[39;49mvalidation_file_id,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/janguy/OneDrive%20-%20Microsoft/Documents/projects/developments/llm-fine-tuning/azureopenai/fine_tunining.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-35-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/janguy/OneDrive%20-%20Microsoft/Documents/projects/developments/llm-fine-tuning/azureopenai/fine_tunining.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/janguy/OneDrive%20-%20Microsoft/Documents/projects/developments/llm-fine-tuning/azureopenai/fine_tunining.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m job_id \u001b[39m=\u001b[39m response[\u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/janguy/OneDrive%20-%20Microsoft/Documents/projects/developments/llm-fine-tuning/azureopenai/fine_tunining.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# You can use the job ID to monitor the status of the fine-tuning job.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/janguy/OneDrive%20-%20Microsoft/Documents/projects/developments/llm-fine-tuning/azureopenai/fine_tunining.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# The fine-tuning job will take some time to start and complete.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\janguy\\AppData\\Local\\miniconda3\\envs\\llm\\lib\\site-packages\\openai\\api_resources\\abstract\\createable_api_resource.py:57\u001b[0m, in \u001b[0;36mCreateableAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m     40\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m     48\u001b[0m ):\n\u001b[0;32m     49\u001b[0m     requestor, url \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m__prepare_create_requestor(\n\u001b[0;32m     50\u001b[0m         api_key,\n\u001b[0;32m     51\u001b[0m         api_base,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m         organization,\n\u001b[0;32m     55\u001b[0m     )\n\u001b[1;32m---> 57\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m     58\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params, request_id\u001b[39m=\u001b[39;49mrequest_id\n\u001b[0;32m     59\u001b[0m     )\n\u001b[0;32m     61\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39mconvert_to_openai_object(\n\u001b[0;32m     62\u001b[0m         response,\n\u001b[0;32m     63\u001b[0m         api_key,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m         plain_old_data\u001b[39m=\u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mplain_old_data,\n\u001b[0;32m     67\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\janguy\\AppData\\Local\\miniconda3\\envs\\llm\\lib\\site-packages\\openai\\api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    279\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    280\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    288\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    290\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    291\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    297\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    298\u001b[0m     )\n\u001b[1;32m--> 299\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\janguy\\AppData\\Local\\miniconda3\\envs\\llm\\lib\\site-packages\\openai\\api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    702\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    703\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    704\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    705\u001b[0m         )\n\u001b[0;32m    706\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    707\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    708\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    709\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 710\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    711\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    712\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    713\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    714\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    715\u001b[0m         ),\n\u001b[0;32m    716\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    717\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\janguy\\AppData\\Local\\miniconda3\\envs\\llm\\lib\\site-packages\\openai\\api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    773\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    774\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 775\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    776\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    777\u001b[0m     )\n\u001b[0;32m    778\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: Resource not found"
     ]
    }
   ],
   "source": [
    "response = openai.FineTuningJob.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=\"gpt-35-turbo\",\n",
    ")\n",
    "\n",
    "job_id = response[\"id\"]\n",
    "\n",
    "# You can use the job ID to monitor the status of the fine-tuning job.\n",
    "# The fine-tuning job will take some time to start and complete.\n",
    "\n",
    "print(\"Job ID:\", response[\"id\"])\n",
    "print(\"Status:\", response[\"status\"])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
